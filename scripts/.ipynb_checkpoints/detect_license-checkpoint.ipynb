{
 "cells": [
  {
   "cell_type": "raw",
   "id": "201c17e3",
   "metadata": {},
   "source": [
    "# Importing librairies\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d6c805f7",
   "metadata": {},
   "source": [
    "# Setting the directories\n",
    "cfg_file = \"../yolov3_files/yolov3.cfg\"  # Path to YOLOv3 configuration file\n",
    "weights_file = \"../yolov3_files/yolov3.weights\"  # Path to YOLOv3 weights file\n",
    "names_file = \"../yolov3_files/coco.names\"  # Path to class names file"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a8022cf2",
   "metadata": {},
   "source": [
    "# Loading YOLO model\n",
    "def load_yolo_model(cfg_file, weights_file, names_file):\n",
    "    net = cv2.dnn.readNet(weights_file, cfg_file)\n",
    "    with open(names_file, 'r') as f:\n",
    "        classes = [line.strip() for line in f.readlines()]\n",
    "    return net, classes"
   ]
  },
  {
   "cell_type": "raw",
   "id": "94e5388b",
   "metadata": {},
   "source": [
    "# Getting the output layer names of YOLO model\n",
    "def get_output_layers(net):\n",
    "    layer_names = net.getLayerNames()\n",
    "    output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "    return output_layers"
   ]
  },
  {
   "cell_type": "raw",
   "id": "736e71ba",
   "metadata": {},
   "source": [
    "# Function to detect license plate\n",
    "\n",
    "def detect_license_plate(img, net, output_layers, conf_threshold=0.5, nms_threshold=0.4):\n",
    "    # Prepare the image for YOLO\n",
    "    blob = cv2.dnn.blobFromImage(img, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    outputs = net.forward(output_layers)\n",
    "\n",
    "    # Initializing lists for detected objects\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "\n",
    "    # Looping over each detection\n",
    "    height, width, _ = img.shape\n",
    "    for output in outputs:\n",
    "        for detection in output:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            \n",
    "            # Filtering detections based on confidence level\n",
    "            if confidence > conf_threshold:\n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "                w = int(detection[2] * width)\n",
    "                h = int(detection[3] * height)\n",
    "\n",
    "                # Get the top-left corner of the bounding box\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "\n",
    "                # Add the detection to the lists\n",
    "                boxes.append([x, y, w, h])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "    # Applying non-maxima suppression to remove redundant boxes\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n",
    "\n",
    "    return indices, boxes, confidences, class_ids"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f36c547b",
   "metadata": {},
   "source": [
    "# Drawing the detected bounding boxes on the image\n",
    "def draw_boxes(img, indices, boxes, confidences, class_ids, classes):\n",
    "    for i in indices.flatten():\n",
    "        x, y, w, h = boxes[i]\n",
    "        label = str(classes[class_ids[i]])\n",
    "        confidence = str(round(confidences[i], 2))\n",
    "        color = (0, 255, 0)  # Green for license plates\n",
    "\n",
    "        # Drawing the rectangle and label\n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), color, 2)\n",
    "        cv2.putText(img, f\"{label} {confidence}\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c856e167",
   "metadata": {},
   "source": [
    "# Function to load the model, run detection, and show the result\n",
    "def main(image_path, cfg_file, weights_file, names_file):\n",
    "    # Loading YOLO model and class names\n",
    "    net, classes = load_yolo_model(cfg_file, weights_file, names_file)\n",
    "\n",
    "    # Loading image\n",
    "    img = cv2.imread(image_path)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert image to RGB for matplotlib\n",
    "\n",
    "    height, width, _ = img.shape\n",
    "\n",
    "    # Output layers\n",
    "    output_layers = get_output_layers(net)\n",
    "\n",
    "    # Detecting license plates\n",
    "    indices, boxes, confidences, class_ids = detect_license_plate(img, net, output_layers)\n",
    "\n",
    "    # Drawing the bounding boxes on the image\n",
    "    img_rgb = draw_boxes(img_rgb, indices, boxes, confidences, class_ids, classes)\n",
    "\n",
    "    # Show the output image in Jupyter notebook using matplotlib\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    # Saving the output image\n",
    "    output_image_path = \"output/detected_license_plate.jpg\"\n",
    "    cv2.imwrite(output_image_path, img)\n",
    "    print(f\"Output saved to {output_image_path}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0d3be343",
   "metadata": {},
   "source": [
    "if __name__ == \"__main__\":\n",
    "    image_path = \"../data/images/Cars1.png\"  # Update with your image path\n",
    "    main(image_path, cfg_file, weights_file, names_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aed1293",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef3bbc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "8cab0677",
   "metadata": {},
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Setting the directories\n",
    "cfg_file = \"../yolov3_files/yolov3.cfg\"  # Path to YOLOv3 configuration file\n",
    "weights_file = \"../yolov3_files/yolov3.weights\"  # Path to YOLOv3 weights file\n",
    "names_file = \"../yolov3_files/coco.names\"  # Path to class names file\n",
    "\n",
    "# Loading YOLO model\n",
    "def load_yolo_model(cfg_file, weights_file, names_file):\n",
    "    net = cv2.dnn.readNet(weights_file, cfg_file)\n",
    "    with open(names_file, 'r') as f:\n",
    "        classes = [line.strip() for line in f.readlines()]\n",
    "    return net, classes\n",
    "\n",
    "# Getting the output layer names of YOLO model\n",
    "def get_output_layers(net):\n",
    "    layer_names = net.getLayerNames()\n",
    "    # Adjusting the code to properly handle unconnected output layers\n",
    "    output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "    return output_layers\n",
    "\n",
    "# Perform license plate detection\n",
    "def detect_license_plate(img, net, output_layers, conf_threshold=0.5, nms_threshold=0.4):\n",
    "    # Prepare the image for YOLO\n",
    "    blob = cv2.dnn.blobFromImage(img, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    outputs = net.forward(output_layers)\n",
    "\n",
    "    # Initializing lists for detected objects\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "\n",
    "    # Looping over each detection\n",
    "    height, width, _ = img.shape\n",
    "    for output in outputs:\n",
    "        for detection in output:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            \n",
    "            # Filtering detections based on confidence level\n",
    "            if confidence > conf_threshold:\n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "                w = int(detection[2] * width)\n",
    "                h = int(detection[3] * height)\n",
    "\n",
    "                # Get the top-left corner of the bounding box\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "\n",
    "                # Add the detection to the lists\n",
    "                boxes.append([x, y, w, h])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "    # Applying non-maxima suppression to remove redundant boxes\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n",
    "\n",
    "    return indices, boxes, confidences, class_ids\n",
    "\n",
    "# Drawing the detected bounding boxes on the image\n",
    "def draw_boxes(img, indices, boxes, confidences, class_ids, classes):\n",
    "    for i in indices.flatten():\n",
    "        x, y, w, h = boxes[i]\n",
    "        label = str(classes[class_ids[i]])\n",
    "        confidence = str(round(confidences[i], 2))\n",
    "        color = (0, 255, 0)  # Green for license plates\n",
    "\n",
    "        # Drawing the rectangle and label\n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), color, 2)\n",
    "        cv2.putText(img, f\"{label} {confidence}\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "\n",
    "    return img\n",
    "\n",
    "# Function to load the model, run detection, and show the result\n",
    "def main(image_path, cfg_file, weights_file, names_file):\n",
    "    # Loading YOLO model and class names\n",
    "    net, classes = load_yolo_model(cfg_file, weights_file, names_file)\n",
    "\n",
    "    # Loading image\n",
    "    img = cv2.imread(image_path)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert image to RGB for matplotlib\n",
    "\n",
    "    height, width, _ = img.shape\n",
    "\n",
    "    # Output layers\n",
    "    output_layers = get_output_layers(net)\n",
    "\n",
    "    # Detecting license plates\n",
    "    indices, boxes, confidences, class_ids = detect_license_plate(img, net, output_layers)\n",
    "\n",
    "    # Drawing the bounding boxes on the image\n",
    "    img_rgb = draw_boxes(img_rgb, indices, boxes, confidences, class_ids, classes)\n",
    "\n",
    "    # Show the output image in Jupyter notebook using matplotlib\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    # Saving the output image\n",
    "    output_image_path = \"output/detected_license_plate.jpg\"\n",
    "    cv2.imwrite(output_image_path, img)\n",
    "    print(f\"Output saved to {output_image_path}\")\n",
    "\n",
    "# Example usage in Jupyter Notebook\n",
    "if __name__ == \"__main__\":\n",
    "    image_path = \"../data/images/Cars1.png\"  # Update with your image path\n",
    "    main(image_path, cfg_file, weights_file, names_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb7fe8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a8d19d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbcbd10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import cv2  # For OpenCV functions\n",
    "import numpy as np  # For numerical computations\n",
    "import matplotlib.pyplot as plt  # For displaying images\n",
    "\n",
    "# Function to load the YOLO model\n",
    "def load_yolo_model(cfg_file, weights_file, names_file):\n",
    "    \"\"\"\n",
    "    Loads the YOLO model and class names.\n",
    "\n",
    "    Args:\n",
    "        cfg_file (str): Path to the YOLO configuration file.\n",
    "        weights_file (str): Path to the YOLO weights file.\n",
    "        names_file (str): Path to the file containing class names.\n",
    "\n",
    "    Returns:\n",
    "        tuple: YOLO network and list of class names.\n",
    "    \"\"\"\n",
    "    # Load the YOLO model\n",
    "    net = cv2.dnn.readNetFromDarknet(cfg_file, weights_file)\n",
    "\n",
    "    # Read class names from the names file\n",
    "    with open(names_file, \"r\") as f:\n",
    "        classes = [line.strip() for line in f.readlines()]\n",
    "    \n",
    "    return net, classes\n",
    "\n",
    "# Function to get the output layer names of YOLO\n",
    "def get_output_layers(net):\n",
    "    \"\"\"\n",
    "    Gets the output layer names of the YOLO model.\n",
    "\n",
    "    Args:\n",
    "        net (cv2.dnn_Net): Loaded YOLO network.\n",
    "\n",
    "    Returns:\n",
    "        list: Names of output layers.\n",
    "    \"\"\"\n",
    "    layer_names = net.getLayerNames()  # Get all layer names\n",
    "    output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]  # Output layer indices\n",
    "    return output_layers\n",
    "\n",
    "# Function to detect objects (license plates) in an image\n",
    "def detect_license(img, net, output_layers, conf_threshold=0.5, nms_threshold=0.4):\n",
    "    \"\"\"\n",
    "    Performs object detection using YOLO.\n",
    "\n",
    "    Args:\n",
    "        img (numpy.ndarray): Input image.\n",
    "        net (cv2.dnn_Net): YOLO network.\n",
    "        output_layers (list): Names of output layers.\n",
    "        conf_threshold (float): Confidence threshold for filtering.\n",
    "        nms_threshold (float): Non-max suppression threshold.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Indices of final detections, bounding boxes, confidences, and class IDs.\n",
    "    \"\"\"\n",
    "    height, width = img.shape[:2]  # Get image dimensions\n",
    "\n",
    "    # Prepare the image for YOLO\n",
    "    blob = cv2.dnn.blobFromImage(img, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "    net.setInput(blob)  # Set the blob as input to the network\n",
    "    outputs = net.forward(output_layers)  # Get network outputs\n",
    "\n",
    "    # Initialize lists to store detection results\n",
    "    boxes, confidences, class_ids = [], [], []\n",
    "\n",
    "    # Process each output\n",
    "    for output in outputs:\n",
    "        for detection in output:\n",
    "            scores = detection[5:]  # Scores for each class\n",
    "            class_id = np.argmax(scores)  # Get class with max score\n",
    "            confidence = scores[class_id]  # Confidence of the detected class\n",
    "\n",
    "            # Filter detections based on confidence\n",
    "            if confidence > conf_threshold:\n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "                w = int(detection[2] * width)\n",
    "                h = int(detection[3] * height)\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "\n",
    "                boxes.append([x, y, w, h])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "    # Apply Non-Maximum Suppression to eliminate redundant boxes\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n",
    "    return indices, boxes, confidences, class_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adbc15e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107f6c33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befe9e75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
